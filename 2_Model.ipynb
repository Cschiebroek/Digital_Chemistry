{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import: standard libraries, plus the classes\n",
    "from model_utils import SingleTaskModelTrainer, MultiTaskModelTrainer\n",
    "from ray import tune\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('modules')\n",
    "from utils_data import get_graphs #will be changed later by Riccardo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just an example, we can think about different params/ranges\n",
    "hp_search_config = {\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"batch_size\": tune.choice([8, 16]),\n",
    "        \"hidden_channels\": tune.choice([32, 64, 128]),\n",
    "        \"num_layers\": tune.choice([2, 3, 4]),\n",
    "        \"num_timesteps\": tune.choice([1, 2, 3]),\n",
    "        \"gamma\": tune.loguniform(0.9, 0.99),\n",
    "        \"Scheduler\": tune.choice([\"ReduceLROnPlateau\", \"ExponentialLR\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously created graphs\n"
     ]
    }
   ],
   "source": [
    "#start with getting the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_graphs_DASH_charge_scaled = get_graphs(train,dash_charges=True,scaled =True,save_graphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to split double: we use the first validation set to tune our hyperparameters, and then a second one to be used for early stopping of the final model. We could have smaller sets I think\n",
    "train_data, val_data = train_test_split(train_graphs_DASH_charge_scaled, test_size=0.2, random_state=2000)\n",
    "val1_data, val2_data = train_test_split(val_data, test_size=0.5, random_state=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because for some reason I run into memory issues, did not have this before, to fix. now it will give crap results for the full thing because much less data\n",
    "from random import sample \n",
    "train_data_hp_opt = sample(train_data, 1000)\n",
    "val_data_hp_opt = sample(val1_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mtl_model = MultiTaskModelTrainer(sandbox=True,verbose=True,name='example_MTL',seed = 18012000,train_data = train_data_hp_opt,val_data=val_data_hp_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 14:40:53,810\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2024-03-21 14:40:56,056\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-21 14:41:03</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:07.63        </td></tr>\n",
       "<tr><td>Memory:      </td><td>44.0/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 1.000: 0.315335176041088<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:P2200)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc                    </th><th>Scheduler    </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  hidden_channels</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  num_timesteps</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  kendall_tau</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_with_ray_a4c0a_00000</td><td>TERMINATED</td><td>129.132.218.153:2021480</td><td>ExponentialLR</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">0.958413</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">0.000606811</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.52228</td><td style=\"text-align: right;\">     0.315335</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th style=\"text-align: right;\">  kendall_tau</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_with_ray_a4c0a_00000</td><td style=\"text-align: right;\">     0.315335</td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 14:41:03,717\tINFO tune.py:1042 -- Total run time: 7.66 seconds (7.63 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.000606810841366676, 'batch_size': 8, 'hidden_channels': 32, 'num_layers': 2, 'num_timesteps': 3, 'gamma': 0.9584126887372598, 'Scheduler': 'ExponentialLR'}\n",
      "Best trial final kendall_tau: 0.315335176041088\n"
     ]
    }
   ],
   "source": [
    "example_mtl_model.tune_hyperparameters(config=hp_search_config,num_samples=1,max_num_epochs=1,gpus_per_trial=1,cpus_per_trial=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=2021480)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/cschiebroek/ray_results/train_model_with_ray_2024-03-21_14-40-56/train_model_with_ray_a4c0a_00000_0_Scheduler=ExponentialLR,batch_size=8,gamma=0.9584,hidden_channels=32,lr=0.0006,num_layers=2,num_2024-03-21_14-40-56/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.4068, Val Loss: 0.3968\n",
      "Epoch 2: Train Loss: 0.3910, Val Loss: 0.3897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m example_mtl_model\u001b[38;5;241m.\u001b[39mtrain_data \u001b[38;5;241m=\u001b[39m train_data\n\u001b[1;32m      3\u001b[0m example_mtl_model\u001b[38;5;241m.\u001b[39mval_data \u001b[38;5;241m=\u001b[39m val1_data\n\u001b[0;32m----> 5\u001b[0m \u001b[43mexample_mtl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mes_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/other/Digital_Chemistry/model_utils.py:208\u001b[0m, in \u001b[0;36mBaseModelTrainer.train_and_validate\u001b[0;34m(self, num_epochs, save_models, es_patience, save_losses, device)\u001b[0m\n\u001b[1;32m    205\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m ExponentialLR(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 208\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(val_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, device)\n\u001b[1;32m    210\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m/localhome/cschiebroek/other/Digital_Chemistry/model_utils.py:431\u001b[0m, in \u001b[0;36mBaseModelTrainer.train\u001b[0;34m(self, loader, model, optimizer, device)\u001b[0m\n\u001b[1;32m    429\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    430\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 431\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    433\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(out, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch_geometric/nn/models/attentive_fp.py:148\u001b[0m, in \u001b[0;36mAttentiveFP.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Atom Embedding:\u001b[39;00m\n\u001b[1;32m    146\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x))\n\u001b[0;32m--> 148\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    149\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    150\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(h, x)\u001b[38;5;241m.\u001b[39mrelu_()\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch_geometric/nn/models/attentive_fp.py:45\u001b[0m, in \u001b[0;36mGATEConv.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, edge_index: Adj, edge_attr: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# edge_updater_type: (x: Tensor, edge_attr: Tensor)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# propagate_type: (x: Tensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[0;32m~/.cache/pyg/message_passing/torch_geometric.nn.models.attentive_fp_GATEConv_edge_updater.py:170\u001b[0m, in \u001b[0;36medge_updater\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    160\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    161\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    162\u001b[0m                 x_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 size_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    167\u001b[0m             )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# End Edge Update Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Begin Edge Update Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch_geometric/nn/models/attentive_fp.py:55\u001b[0m, in \u001b[0;36mGATEConv.edge_update\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21medge_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n\u001b[1;32m     53\u001b[0m                 index: Tensor, ptr: OptTensor,\n\u001b[1;32m     54\u001b[0m                 size_i: Optional[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 55\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     alpha_j \u001b[38;5;241m=\u001b[39m (x_j \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_l\u001b[38;5;241m.\u001b[39mt())\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m     alpha_i \u001b[38;5;241m=\u001b[39m (x_i \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_r\u001b[38;5;241m.\u001b[39mt())\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#change the train and val data back first\n",
    "example_mtl_model.train_data = train_data\n",
    "example_mtl_model.val_data = val1_data\n",
    "\n",
    "example_mtl_model.train_and_validate(num_epochs=50, save_models=True, es_patience=10, save_losses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously created graphs\n",
      "tensor([[-0.5214, -0.7871, -0.9921, -0.9109, -0.9067, -0.1491, -0.9188, -0.9088,\n",
      "         -1.0701, -0.9206, -0.9765, -1.0306, -0.0363, -0.8770],\n",
      "        [-0.4625, -0.4841, -0.8560, -0.9216, -1.0713, -0.1384, -0.9661, -0.9778,\n",
      "         -0.9552, -0.9406, -0.9719, -1.0371, -0.6547, -0.2935],\n",
      "        [-0.6098, -0.2845, -0.8240, -0.9208, -1.0263, -0.2171, -0.9865, -0.9963,\n",
      "         -0.8447, -0.9473, -0.9377, -0.9593, -0.0413, -0.2785],\n",
      "        [-0.9883, -0.9365, -1.0168, -1.1672, -1.0389, -1.1151, -1.1015, -0.6023,\n",
      "         -1.0092, -1.0607, -1.0325, -1.1102, -0.0531,  0.5089],\n",
      "        [-0.1845, -0.6231, -0.5642, -1.0305, -0.9269,  0.4017, -1.0493, -1.0526,\n",
      "         -0.8965, -1.0288, -0.9095, -1.0694, -0.4504, -0.4449],\n",
      "        [-0.3976, -0.5278, -0.6276, -1.0880, -1.0510, -0.0174, -1.0960, -1.1113,\n",
      "         -0.7685, -0.9971, -0.9589, -1.0912, -0.3168, -0.3657],\n",
      "        [-0.6970, -0.0869, -0.9033, -0.8946, -1.0130, -0.1053, -0.9602, -0.9756,\n",
      "         -0.9136, -0.9233, -0.9744, -0.9624, -0.0310, -0.6538],\n",
      "        [-0.8754,  0.1796, -1.0149, -0.9531, -1.0465, -1.0357, -0.8926, -0.8793,\n",
      "         -0.9811, -0.9570, -0.9631, -0.9245, -0.5721, -0.6603],\n",
      "        [-0.7011,  0.2119, -0.9674, -0.9192, -1.0639, -1.1155, -0.8815, -0.9389,\n",
      "         -0.9876, -0.8716, -0.9855, -0.8401, -0.7210, -0.0974],\n",
      "        [-0.9005,  0.2235, -1.0148, -0.9832, -1.0404, -0.9125, -0.9427, -0.9905,\n",
      "         -0.9918, -0.9795, -0.9575, -0.9770, -0.6233, -0.8041],\n",
      "        [-0.8625,  0.0841, -1.0164, -0.9715, -1.0217, -0.7341, -0.9486, -0.9911,\n",
      "         -0.9990, -0.9728, -0.9665, -0.9679, -0.4140, -0.7758],\n",
      "        [-0.8372, -0.0084, -0.9803, -0.9949, -1.0487, -0.7290, -0.9399, -0.8667,\n",
      "         -0.9724, -0.9981, -0.9901, -1.0003, -0.5494, -0.7259],\n",
      "        [ 0.0113, -0.5527, -0.3606, -1.0264, -0.9419,  0.3308, -1.0795, -1.0541,\n",
      "         -0.7178, -1.0090, -0.7804, -1.0483, -0.5487, -0.1176],\n",
      "        [-0.9459,  0.0311, -1.0140, -0.9816, -1.0309, -0.9925, -0.9886, -0.9334,\n",
      "         -1.0022, -0.9904, -0.9862, -0.9641, -0.4914, -0.4344],\n",
      "        [-0.6400, -0.6942, -0.9947, -0.9971, -1.0149,  0.0777, -1.0744, -1.0763,\n",
      "         -1.0366, -1.0350, -1.0263, -1.0721, -0.0747, -0.7102],\n",
      "        [-0.9064,  0.3136, -1.0379, -0.9906, -1.0506, -0.9855, -0.9161, -0.9346,\n",
      "         -0.9662, -0.9906, -0.9839, -0.9192, -0.8085, -0.6566],\n",
      "        [-0.9328,  0.1878, -1.0456, -1.0021, -1.0349, -0.9997, -0.9438, -0.8801,\n",
      "         -0.9946, -0.9960, -0.9665, -0.9868, -0.6669, -0.7338],\n",
      "        [-0.9432,  0.2232, -1.0495, -1.0058, -1.0364, -1.0221, -0.9406, -0.8629,\n",
      "         -0.9985, -0.9977, -0.9652, -0.9853, -0.6978, -0.7581],\n",
      "        [-0.8370, -0.0263, -0.9929, -0.9996, -1.0555, -0.6039, -0.9878, -1.0059,\n",
      "         -0.9814, -0.9914, -0.9734, -0.9948, -0.5061, -0.6332],\n",
      "        [-0.9477,  0.3694, -1.0520, -1.0082, -1.0369, -1.0032, -0.9377, -0.9428,\n",
      "         -0.9674, -1.0012, -0.9832, -0.9897, -0.8888, -0.8533],\n",
      "        [-0.8956,  0.2531, -1.0151, -1.0233, -1.0492, -0.7814, -0.9759, -1.0544,\n",
      "         -0.9714, -1.0208, -0.9693, -1.0173, -0.8046, -0.7624],\n",
      "        [-0.9024,  0.2339, -1.0394, -0.9541, -1.0596, -1.0340, -0.8764, -0.8113,\n",
      "         -0.9805, -0.9707, -0.9582, -0.9351, -0.6950, -0.7878],\n",
      "        [-0.8927,  0.2060, -1.0028, -0.9813, -1.0361, -0.9501, -0.9454, -0.9770,\n",
      "         -0.9739, -0.9827, -0.9671, -0.9507, -0.5859, -0.6233],\n",
      "        [-0.8954, -0.0169, -0.9941, -1.0129, -1.0707, -0.6814, -1.0192, -1.0364,\n",
      "         -0.9797, -1.0183, -0.9676, -1.0210, -0.4526, -0.6071],\n",
      "        [-0.9420,  0.2685, -1.0176, -0.9861, -1.0485, -1.0447, -0.9103, -0.8474,\n",
      "         -0.9747, -0.9856, -0.9576, -0.9796, -0.7072, -0.7940],\n",
      "        [-0.3425, -0.6431, -0.6632, -1.0699, -1.0286,  0.2038, -1.0860, -1.0727,\n",
      "         -0.8977, -1.0534, -0.9325, -1.1341, -0.5710, -0.3779],\n",
      "        [-0.5001, -0.7323, -0.8946, -0.9696, -0.9672,  0.0978, -0.9550, -0.9847,\n",
      "         -1.0110, -0.9632, -0.9493, -1.0602, -0.3354, -0.6563],\n",
      "        [-0.7799, -0.0739, -0.9381, -1.0312, -1.1089, -0.2442, -1.0077, -1.0827,\n",
      "         -0.9668, -1.0146, -1.0098, -1.1012, -0.8223, -0.7084],\n",
      "        [-0.9290,  0.1654, -1.0196, -0.9897, -1.0359, -1.0093, -0.9130, -0.7482,\n",
      "         -0.9658, -0.9832, -0.9857, -0.9870, -0.6664, -0.7414],\n",
      "        [-0.9027,  0.2234, -1.0334, -0.9277, -1.0549, -1.0255, -0.9107, -0.8632,\n",
      "         -0.9869, -0.9810, -0.9469, -0.9611, -0.6536, -0.8316],\n",
      "        [-0.8824, -0.2290, -0.9450, -0.9751, -1.0596, -0.6999, -1.0240, -0.9999,\n",
      "         -0.9638, -1.0269, -0.9783, -1.0030, -0.2921, -0.1968],\n",
      "        [-1.0112,  0.1164, -1.0285, -1.0477, -1.0498, -1.0492, -0.9981, -0.6973,\n",
      "         -0.9973, -1.0075, -0.9759, -1.0580, -0.7861, -0.7133]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#example: how to load and predict\n",
    "import torch\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "import pickle\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "model = AttentiveFP(in_channels=24, hidden_channels=200, out_channels=14,\n",
    "                    edge_dim=11, num_layers=2, num_timesteps=2,\n",
    "                    dropout=0.0)\n",
    "model.load_state_dict(torch.load(\"/localhome/cschiebroek/other/Digital_Chemistry/sandbox/models/example_MTL_seed_18012000.pt\"))\n",
    "model.eval()\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_graphs_DASH_charge_scaled = get_graphs(train,dash_charges=True,scaled =True,save_graphs = True)\n",
    "train_loader = DataLoader(train_graphs_DASH_charge_scaled, batch_size=32, shuffle=False)\n",
    "for data in train_loader:\n",
    "    out = model(data.x, data.edge_index, data.edge_attr,data.batch)\n",
    "    print(out)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5214, -0.7871, -0.9921, -0.9109, -0.9067, -0.1491, -0.9188, -0.9088,\n",
      "         -1.0701, -0.9206, -0.9765, -1.0306, -0.0363, -0.8770],\n",
      "        [-0.4625, -0.4841, -0.8560, -0.9216, -1.0713, -0.1384, -0.9661, -0.9778,\n",
      "         -0.9552, -0.9406, -0.9719, -1.0371, -0.6547, -0.2935],\n",
      "        [-0.6098, -0.2845, -0.8240, -0.9208, -1.0263, -0.2171, -0.9865, -0.9963,\n",
      "         -0.8447, -0.9473, -0.9377, -0.9593, -0.0413, -0.2785],\n",
      "        [-0.9883, -0.9365, -1.0168, -1.1672, -1.0389, -1.1151, -1.1015, -0.6023,\n",
      "         -1.0092, -1.0607, -1.0325, -1.1102, -0.0531,  0.5089],\n",
      "        [-0.1845, -0.6231, -0.5642, -1.0305, -0.9269,  0.4017, -1.0493, -1.0526,\n",
      "         -0.8965, -1.0288, -0.9095, -1.0694, -0.4504, -0.4449],\n",
      "        [-0.3976, -0.5278, -0.6276, -1.0880, -1.0510, -0.0174, -1.0960, -1.1113,\n",
      "         -0.7685, -0.9971, -0.9589, -1.0912, -0.3168, -0.3657],\n",
      "        [-0.6970, -0.0869, -0.9033, -0.8946, -1.0130, -0.1053, -0.9602, -0.9756,\n",
      "         -0.9136, -0.9233, -0.9744, -0.9624, -0.0310, -0.6538],\n",
      "        [-0.8754,  0.1796, -1.0149, -0.9531, -1.0465, -1.0357, -0.8926, -0.8793,\n",
      "         -0.9811, -0.9570, -0.9631, -0.9245, -0.5721, -0.6603],\n",
      "        [-0.7011,  0.2119, -0.9674, -0.9192, -1.0639, -1.1155, -0.8815, -0.9389,\n",
      "         -0.9876, -0.8716, -0.9855, -0.8401, -0.7210, -0.0974],\n",
      "        [-0.9005,  0.2235, -1.0148, -0.9832, -1.0404, -0.9125, -0.9427, -0.9905,\n",
      "         -0.9918, -0.9795, -0.9575, -0.9770, -0.6233, -0.8041],\n",
      "        [-0.8625,  0.0841, -1.0164, -0.9715, -1.0217, -0.7341, -0.9486, -0.9911,\n",
      "         -0.9990, -0.9728, -0.9665, -0.9679, -0.4140, -0.7758],\n",
      "        [-0.8372, -0.0084, -0.9803, -0.9949, -1.0487, -0.7290, -0.9399, -0.8667,\n",
      "         -0.9724, -0.9981, -0.9901, -1.0003, -0.5494, -0.7259],\n",
      "        [ 0.0113, -0.5527, -0.3606, -1.0264, -0.9419,  0.3308, -1.0795, -1.0541,\n",
      "         -0.7178, -1.0090, -0.7804, -1.0483, -0.5487, -0.1176],\n",
      "        [-0.9459,  0.0311, -1.0140, -0.9816, -1.0309, -0.9925, -0.9886, -0.9334,\n",
      "         -1.0022, -0.9904, -0.9862, -0.9641, -0.4914, -0.4344],\n",
      "        [-0.6400, -0.6942, -0.9947, -0.9971, -1.0149,  0.0777, -1.0744, -1.0763,\n",
      "         -1.0366, -1.0350, -1.0263, -1.0721, -0.0747, -0.7102],\n",
      "        [-0.9064,  0.3136, -1.0379, -0.9906, -1.0506, -0.9855, -0.9161, -0.9346,\n",
      "         -0.9662, -0.9906, -0.9839, -0.9192, -0.8085, -0.6566],\n",
      "        [-0.9328,  0.1878, -1.0456, -1.0021, -1.0349, -0.9997, -0.9438, -0.8801,\n",
      "         -0.9946, -0.9960, -0.9665, -0.9868, -0.6669, -0.7338],\n",
      "        [-0.9432,  0.2232, -1.0495, -1.0058, -1.0364, -1.0221, -0.9406, -0.8629,\n",
      "         -0.9985, -0.9977, -0.9652, -0.9853, -0.6978, -0.7581],\n",
      "        [-0.8370, -0.0263, -0.9929, -0.9996, -1.0555, -0.6039, -0.9878, -1.0059,\n",
      "         -0.9814, -0.9914, -0.9734, -0.9948, -0.5061, -0.6332],\n",
      "        [-0.9477,  0.3694, -1.0520, -1.0082, -1.0369, -1.0032, -0.9377, -0.9428,\n",
      "         -0.9674, -1.0012, -0.9832, -0.9897, -0.8888, -0.8533],\n",
      "        [-0.8956,  0.2531, -1.0151, -1.0233, -1.0492, -0.7814, -0.9759, -1.0544,\n",
      "         -0.9714, -1.0208, -0.9693, -1.0173, -0.8046, -0.7624],\n",
      "        [-0.9024,  0.2339, -1.0394, -0.9541, -1.0596, -1.0340, -0.8764, -0.8113,\n",
      "         -0.9805, -0.9707, -0.9582, -0.9351, -0.6950, -0.7878],\n",
      "        [-0.8927,  0.2060, -1.0028, -0.9813, -1.0361, -0.9501, -0.9454, -0.9770,\n",
      "         -0.9739, -0.9827, -0.9671, -0.9507, -0.5859, -0.6233],\n",
      "        [-0.8954, -0.0169, -0.9941, -1.0129, -1.0707, -0.6814, -1.0192, -1.0364,\n",
      "         -0.9797, -1.0183, -0.9676, -1.0210, -0.4526, -0.6071],\n",
      "        [-0.9420,  0.2685, -1.0176, -0.9861, -1.0485, -1.0447, -0.9103, -0.8474,\n",
      "         -0.9747, -0.9856, -0.9576, -0.9796, -0.7072, -0.7940],\n",
      "        [-0.3425, -0.6431, -0.6632, -1.0699, -1.0286,  0.2038, -1.0860, -1.0727,\n",
      "         -0.8977, -1.0534, -0.9325, -1.1341, -0.5710, -0.3779],\n",
      "        [-0.5001, -0.7323, -0.8946, -0.9696, -0.9672,  0.0978, -0.9550, -0.9847,\n",
      "         -1.0110, -0.9632, -0.9493, -1.0602, -0.3354, -0.6563],\n",
      "        [-0.7799, -0.0739, -0.9381, -1.0312, -1.1089, -0.2442, -1.0077, -1.0827,\n",
      "         -0.9668, -1.0146, -1.0098, -1.1012, -0.8223, -0.7084],\n",
      "        [-0.9290,  0.1654, -1.0196, -0.9897, -1.0359, -1.0093, -0.9130, -0.7482,\n",
      "         -0.9658, -0.9832, -0.9857, -0.9870, -0.6664, -0.7414],\n",
      "        [-0.9027,  0.2234, -1.0334, -0.9277, -1.0549, -1.0255, -0.9107, -0.8632,\n",
      "         -0.9869, -0.9810, -0.9469, -0.9611, -0.6536, -0.8316],\n",
      "        [-0.8824, -0.2290, -0.9450, -0.9751, -1.0596, -0.6999, -1.0240, -0.9999,\n",
      "         -0.9638, -1.0269, -0.9783, -1.0030, -0.2921, -0.1968],\n",
      "        [-1.0112,  0.1164, -1.0285, -1.0477, -1.0498, -1.0492, -0.9981, -0.6973,\n",
      "         -0.9973, -1.0075, -0.9759, -1.0580, -0.7861, -0.7133]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "torch.save(model,'model_full_test.pt')\n",
    "#load model\n",
    "model = torch.load('model_full_test.pt')\n",
    "train_loader = DataLoader(train_graphs_DASH_charge_scaled, batch_size=32, shuffle=False)\n",
    "for data in train_loader:\n",
    "    out = model(data.x, data.edge_index, data.edge_attr,data.batch)\n",
    "    print(out)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.nn.models.attentive_fp.AttentiveFP"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtl_dc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
