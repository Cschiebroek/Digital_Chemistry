{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import: standard libraries, plus the classes\n",
    "import sys\n",
    "sys.path.append('modules')\n",
    "from model_utils import SingleTaskModelTrainer, MultiTaskModelTrainer\n",
    "from ray import tune\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils_data import get_graphs #will be changed later by Riccardo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just an example, we can think about different params/ranges\n",
    "hp_search_config = {\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"batch_size\": tune.choice([8, 16]),\n",
    "        \"hidden_channels\": tune.choice([32, 64, 128]),\n",
    "        \"num_layers\": tune.choice([2, 3, 4]),\n",
    "        \"num_timesteps\": tune.choice([1, 2, 3]),\n",
    "        \"gamma\": tune.loguniform(0.9, 0.99),\n",
    "        \"Scheduler\": tune.choice([\"ReduceLROnPlateau\", \"ExponentialLR\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously created graphs\n"
     ]
    }
   ],
   "source": [
    "#start with getting the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_graphs_DASH_charge_scaled = get_graphs(train,dash_charges=True,scaled =True,save_graphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to split double: we use the first validation set to tune our hyperparameters, and then a second one to be used for early stopping of the final model. We could have smaller sets I think\n",
    "train_data, val_data = train_test_split(train_graphs_DASH_charge_scaled, test_size=0.2, random_state=2000)\n",
    "val1_data, val2_data = train_test_split(val_data, test_size=0.5, random_state=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because for some reason I run into memory issues, did not have this before, to fix. now it will give crap results for the full thing because much less data\n",
    "from random import sample \n",
    "train_data_hp_opt = sample(train_data, 1000)\n",
    "val_data_hp_opt = sample(val1_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mtl_model = MultiTaskModelTrainer(sandbox=True,verbose=True,name='example_MTL',seed = 18012000,train_data = train_data,val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 15:39:03,158\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2024-03-26 15:39:42,683\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-26 15:40:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:35.29        </td></tr>\n",
       "<tr><td>Memory:      </td><td>57.5/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 1.000: None<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:P2200)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc                    </th><th>Scheduler    </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  hidden_channels</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  num_timesteps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_with_ray_aeddf_00000</td><td>RUNNING </td><td>129.132.218.153:3512460</td><td>ExponentialLR</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">0.958413</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">0.000606811</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">              3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 3631 MiB, 1 objects, write throughput 944 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 18154 MiB, 2 objects, write throughput 1150 MiB/s.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught unexpected exception: Task was killed due to the node running low on memory.\nMemory on the node (IP: 129.132.218.153, ID: 7928212460c05437fed5da507452cfb355b22f9997128468d699c818) where the task (actor ID: 28b1ee23209e234a11e4ba4b01000000, name=ImplicitFunc.__init__, pid=3512460, memory used=26.17GB) was running was 59.42GB / 62.51GB (0.950628), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: a1f44d4397e7e81b7454cb720688aee795b2a21d3fa99d5e4e78467a) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 129.132.218.153`. To see the logs of the worker, use `ray logs worker-a1f44d4397e7e81b7454cb720688aee795b2a21d3fa99d5e4e78467a*out -ip 129.132.218.153. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n3512460\t26.17\tray::ImplicitFunc.train\n3510967\t15.41\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\n3088119\t1.06\t/snap/firefox/3941/usr/lib/firefox/firefox\n3510045\t0.61\t/snap/code/155/usr/share/code/code /home/cschiebroek/.vscode/extensions/ms-python.vscode-pylance-202...\n3476072\t0.55\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\n3488189\t0.38\t/snap/firefox/3941/usr/lib/firefox/firefox -contentproc -childID 291 -isForBrowser -prefsLen 31265 -...\n2212879\t0.38\t/snap/zoom-client/225/zoom/zoom\n2336\t0.38\t/usr/bin/gnome-shell\n3088937\t0.35\t/snap/firefox/3941/usr/lib/firefox/firefox -contentproc -childID 8 -isForBrowser -prefsLen 31018 -pr...\n3395401\t0.34\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py:110\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:22\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m auto_init_ray()\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/_private/worker.py:2626\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2626\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_individual_id:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 129.132.218.153, ID: 7928212460c05437fed5da507452cfb355b22f9997128468d699c818) where the task (actor ID: 28b1ee23209e234a11e4ba4b01000000, name=ImplicitFunc.__init__, pid=3512460, memory used=26.17GB) was running was 59.42GB / 62.51GB (0.950628), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: a1f44d4397e7e81b7454cb720688aee795b2a21d3fa99d5e4e78467a) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 129.132.218.153`. To see the logs of the worker, use `ray logs worker-a1f44d4397e7e81b7454cb720688aee795b2a21d3fa99d5e4e78467a*out -ip 129.132.218.153. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n3512460\t26.17\tray::ImplicitFunc.train\n3510967\t15.41\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\n3088119\t1.06\t/snap/firefox/3941/usr/lib/firefox/firefox\n3510045\t0.61\t/snap/code/155/usr/share/code/code /home/cschiebroek/.vscode/extensions/ms-python.vscode-pylance-202...\n3476072\t0.55\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\n3488189\t0.38\t/snap/firefox/3941/usr/lib/firefox/firefox -contentproc -childID 291 -isForBrowser -prefsLen 31265 -...\n2212879\t0.38\t/snap/zoom-client/225/zoom/zoom\n2336\t0.38\t/usr/bin/gnome-shell\n3088937\t0.35\t/snap/firefox/3941/usr/lib/firefox/firefox -contentproc -childID 8 -isForBrowser -prefsLen 31018 -pr...\n3395401\t0.34\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexample_mtl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp_search_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_num_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcpus_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/other/Digital_Chemistry/modules/model_utils.py:778\u001b[0m, in \u001b[0;36mMultiTaskModelTrainer.tune_hyperparameters\u001b[0;34m(self, config, num_samples, max_num_epochs, gpus_per_trial, cpus_per_trial)\u001b[0m\n\u001b[1;32m    775\u001b[0m data_train_ref \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data)\n\u001b[1;32m    776\u001b[0m data_val_ref \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data)\n\u001b[0;32m--> 778\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model_with_ray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_train_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_val_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_input_feautures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_input_feautures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpus_per_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_best_trial(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkendall_tau\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mconfig))\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/tune/tune.py:1002\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m-> 1002\u001b[0m         \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n\u001b[1;32m   1004\u001b[0m             _report_progress(runner, progress_reporter)\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:728\u001b[0m, in \u001b[0;36mTuneController.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_add_actors()\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnum_live_actors:\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_resources_manager\u001b[38;5;241m.\u001b[39mon_no_available_trials(\n\u001b[1;32m    733\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_trials()\n\u001b[1;32m    734\u001b[0m         )\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:224\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_state_events\u001b[38;5;241m.\u001b[39mresolve_future(future)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m actor_task_futures:\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_task_events\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_ready_resource_future()\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py:113\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_error:\n\u001b[0;32m--> 113\u001b[0m         \u001b[43mon_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:770\u001b[0m, in \u001b[0;36mRayActorManager._schedule_tracked_actor_task.<locals>.on_error\u001b[0;34m(exception)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_error\u001b[39m(exception: \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_task_failed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracked_actor_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracked_actor_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexception\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:291\u001b[0m, in \u001b[0;36mRayActorManager._actor_task_failed\u001b[0;34m(self, tracked_actor_task, exception)\u001b[0m\n\u001b[1;32m    289\u001b[0m         tracked_actor_task\u001b[38;5;241m.\u001b[39m_on_error(tracked_actor, exception)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaught unexpected exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught unexpected exception: Task was killed due to the node running low on memory.\nMemory on the node (IP: 129.132.218.153, ID: 7928212460c05437fed5da507452cfb355b22f9997128468d699c818) where the task (actor ID: 28b1ee23209e234a11e4ba4b01000000, name=ImplicitFunc.__init__, pid=3512460, memory used=26.17GB) was running was 59.42GB / 62.51GB (0.950628), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: a1f44d4397e7e81b7454cb720688aee795b2a21d3fa99d5e4e78467a) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 129.132.218.153`. To see the logs of the worker, use `ray logs worker-a1f44d4397e7e81b7454cb720688aee795b2a21d3fa99d5e4e78467a*out -ip 129.132.218.153. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n3512460\t26.17\tray::ImplicitFunc.train\n3510967\t15.41\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\n3088119\t1.06\t/snap/firefox/3941/usr/lib/firefox/firefox\n3510045\t0.61\t/snap/code/155/usr/share/code/code /home/cschiebroek/.vscode/extensions/ms-python.vscode-pylance-202...\n3476072\t0.55\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\n3488189\t0.38\t/snap/firefox/3941/usr/lib/firefox/firefox -contentproc -childID 291 -isForBrowser -prefsLen 31265 -...\n2212879\t0.38\t/snap/zoom-client/225/zoom/zoom\n2336\t0.38\t/usr/bin/gnome-shell\n3088937\t0.35\t/snap/firefox/3941/usr/lib/firefox/firefox -contentproc -childID 8 -isForBrowser -prefsLen 31018 -pr...\n3395401\t0.34\t/localhome/cschiebroek/.conda/envs/mtl_dc/bin/python -m ipykernel_launcher --f=/home/cschiebroek/.lo...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 15:41:03,102 E 3511293 3511293] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7928212460c05437fed5da507452cfb355b22f9997128468d699c818, IP: 129.132.218.153) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 129.132.218.153`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:06:03,121 E 3511293 3511293] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7928212460c05437fed5da507452cfb355b22f9997128468d699c818, IP: 129.132.218.153) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 129.132.218.153`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:10:03,124 E 3511293 3511293] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7928212460c05437fed5da507452cfb355b22f9997128468d699c818, IP: 129.132.218.153) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 129.132.218.153`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "example_mtl_model.tune_hyperparameters(config=hp_search_config,num_samples=1,max_num_epochs=1,gpus_per_trial=1,cpus_per_trial=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=2021480)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/cschiebroek/ray_results/train_model_with_ray_2024-03-21_14-40-56/train_model_with_ray_a4c0a_00000_0_Scheduler=ExponentialLR,batch_size=8,gamma=0.9584,hidden_channels=32,lr=0.0006,num_layers=2,num_2024-03-21_14-40-56/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.4068, Val Loss: 0.3968\n",
      "Epoch 2: Train Loss: 0.3910, Val Loss: 0.3897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m example_mtl_model\u001b[38;5;241m.\u001b[39mtrain_data \u001b[38;5;241m=\u001b[39m train_data\n\u001b[1;32m      3\u001b[0m example_mtl_model\u001b[38;5;241m.\u001b[39mval_data \u001b[38;5;241m=\u001b[39m val1_data\n\u001b[0;32m----> 5\u001b[0m \u001b[43mexample_mtl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mes_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/other/Digital_Chemistry/model_utils.py:208\u001b[0m, in \u001b[0;36mBaseModelTrainer.train_and_validate\u001b[0;34m(self, num_epochs, save_models, es_patience, save_losses, device)\u001b[0m\n\u001b[1;32m    205\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m ExponentialLR(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 208\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(val_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, device)\n\u001b[1;32m    210\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m/localhome/cschiebroek/other/Digital_Chemistry/model_utils.py:431\u001b[0m, in \u001b[0;36mBaseModelTrainer.train\u001b[0;34m(self, loader, model, optimizer, device)\u001b[0m\n\u001b[1;32m    429\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    430\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 431\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    433\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(out, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch_geometric/nn/models/attentive_fp.py:148\u001b[0m, in \u001b[0;36mAttentiveFP.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Atom Embedding:\u001b[39;00m\n\u001b[1;32m    146\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x))\n\u001b[0;32m--> 148\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    149\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(h, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    150\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(h, x)\u001b[38;5;241m.\u001b[39mrelu_()\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch_geometric/nn/models/attentive_fp.py:45\u001b[0m, in \u001b[0;36mGATEConv.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, edge_index: Adj, edge_attr: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# edge_updater_type: (x: Tensor, edge_attr: Tensor)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# propagate_type: (x: Tensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[0;32m~/.cache/pyg/message_passing/torch_geometric.nn.models.attentive_fp_GATEConv_edge_updater.py:170\u001b[0m, in \u001b[0;36medge_updater\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    160\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    161\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    162\u001b[0m                 x_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 size_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    167\u001b[0m             )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# End Edge Update Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Begin Edge Update Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/localhome/cschiebroek/.conda/envs/mtl_dc/lib/python3.11/site-packages/torch_geometric/nn/models/attentive_fp.py:55\u001b[0m, in \u001b[0;36mGATEConv.edge_update\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21medge_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n\u001b[1;32m     53\u001b[0m                 index: Tensor, ptr: OptTensor,\n\u001b[1;32m     54\u001b[0m                 size_i: Optional[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 55\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     alpha_j \u001b[38;5;241m=\u001b[39m (x_j \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_l\u001b[38;5;241m.\u001b[39mt())\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m     alpha_i \u001b[38;5;241m=\u001b[39m (x_i \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_r\u001b[38;5;241m.\u001b[39mt())\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#change the train and val data back first\n",
    "example_mtl_model.train_data = train_data\n",
    "example_mtl_model.val_data = val1_data\n",
    "\n",
    "example_mtl_model.train_and_validate(num_epochs=50, save_models=True, es_patience=10, save_losses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously created graphs\n",
      "tensor([[-0.5214, -0.7871, -0.9921, -0.9109, -0.9067, -0.1491, -0.9188, -0.9088,\n",
      "         -1.0701, -0.9206, -0.9765, -1.0306, -0.0363, -0.8770],\n",
      "        [-0.4625, -0.4841, -0.8560, -0.9216, -1.0713, -0.1384, -0.9661, -0.9778,\n",
      "         -0.9552, -0.9406, -0.9719, -1.0371, -0.6547, -0.2935],\n",
      "        [-0.6098, -0.2845, -0.8240, -0.9208, -1.0263, -0.2171, -0.9865, -0.9963,\n",
      "         -0.8447, -0.9473, -0.9377, -0.9593, -0.0413, -0.2785],\n",
      "        [-0.9883, -0.9365, -1.0168, -1.1672, -1.0389, -1.1151, -1.1015, -0.6023,\n",
      "         -1.0092, -1.0607, -1.0325, -1.1102, -0.0531,  0.5089],\n",
      "        [-0.1845, -0.6231, -0.5642, -1.0305, -0.9269,  0.4017, -1.0493, -1.0526,\n",
      "         -0.8965, -1.0288, -0.9095, -1.0694, -0.4504, -0.4449],\n",
      "        [-0.3976, -0.5278, -0.6276, -1.0880, -1.0510, -0.0174, -1.0960, -1.1113,\n",
      "         -0.7685, -0.9971, -0.9589, -1.0912, -0.3168, -0.3657],\n",
      "        [-0.6970, -0.0869, -0.9033, -0.8946, -1.0130, -0.1053, -0.9602, -0.9756,\n",
      "         -0.9136, -0.9233, -0.9744, -0.9624, -0.0310, -0.6538],\n",
      "        [-0.8754,  0.1796, -1.0149, -0.9531, -1.0465, -1.0357, -0.8926, -0.8793,\n",
      "         -0.9811, -0.9570, -0.9631, -0.9245, -0.5721, -0.6603],\n",
      "        [-0.7011,  0.2119, -0.9674, -0.9192, -1.0639, -1.1155, -0.8815, -0.9389,\n",
      "         -0.9876, -0.8716, -0.9855, -0.8401, -0.7210, -0.0974],\n",
      "        [-0.9005,  0.2235, -1.0148, -0.9832, -1.0404, -0.9125, -0.9427, -0.9905,\n",
      "         -0.9918, -0.9795, -0.9575, -0.9770, -0.6233, -0.8041],\n",
      "        [-0.8625,  0.0841, -1.0164, -0.9715, -1.0217, -0.7341, -0.9486, -0.9911,\n",
      "         -0.9990, -0.9728, -0.9665, -0.9679, -0.4140, -0.7758],\n",
      "        [-0.8372, -0.0084, -0.9803, -0.9949, -1.0487, -0.7290, -0.9399, -0.8667,\n",
      "         -0.9724, -0.9981, -0.9901, -1.0003, -0.5494, -0.7259],\n",
      "        [ 0.0113, -0.5527, -0.3606, -1.0264, -0.9419,  0.3308, -1.0795, -1.0541,\n",
      "         -0.7178, -1.0090, -0.7804, -1.0483, -0.5487, -0.1176],\n",
      "        [-0.9459,  0.0311, -1.0140, -0.9816, -1.0309, -0.9925, -0.9886, -0.9334,\n",
      "         -1.0022, -0.9904, -0.9862, -0.9641, -0.4914, -0.4344],\n",
      "        [-0.6400, -0.6942, -0.9947, -0.9971, -1.0149,  0.0777, -1.0744, -1.0763,\n",
      "         -1.0366, -1.0350, -1.0263, -1.0721, -0.0747, -0.7102],\n",
      "        [-0.9064,  0.3136, -1.0379, -0.9906, -1.0506, -0.9855, -0.9161, -0.9346,\n",
      "         -0.9662, -0.9906, -0.9839, -0.9192, -0.8085, -0.6566],\n",
      "        [-0.9328,  0.1878, -1.0456, -1.0021, -1.0349, -0.9997, -0.9438, -0.8801,\n",
      "         -0.9946, -0.9960, -0.9665, -0.9868, -0.6669, -0.7338],\n",
      "        [-0.9432,  0.2232, -1.0495, -1.0058, -1.0364, -1.0221, -0.9406, -0.8629,\n",
      "         -0.9985, -0.9977, -0.9652, -0.9853, -0.6978, -0.7581],\n",
      "        [-0.8370, -0.0263, -0.9929, -0.9996, -1.0555, -0.6039, -0.9878, -1.0059,\n",
      "         -0.9814, -0.9914, -0.9734, -0.9948, -0.5061, -0.6332],\n",
      "        [-0.9477,  0.3694, -1.0520, -1.0082, -1.0369, -1.0032, -0.9377, -0.9428,\n",
      "         -0.9674, -1.0012, -0.9832, -0.9897, -0.8888, -0.8533],\n",
      "        [-0.8956,  0.2531, -1.0151, -1.0233, -1.0492, -0.7814, -0.9759, -1.0544,\n",
      "         -0.9714, -1.0208, -0.9693, -1.0173, -0.8046, -0.7624],\n",
      "        [-0.9024,  0.2339, -1.0394, -0.9541, -1.0596, -1.0340, -0.8764, -0.8113,\n",
      "         -0.9805, -0.9707, -0.9582, -0.9351, -0.6950, -0.7878],\n",
      "        [-0.8927,  0.2060, -1.0028, -0.9813, -1.0361, -0.9501, -0.9454, -0.9770,\n",
      "         -0.9739, -0.9827, -0.9671, -0.9507, -0.5859, -0.6233],\n",
      "        [-0.8954, -0.0169, -0.9941, -1.0129, -1.0707, -0.6814, -1.0192, -1.0364,\n",
      "         -0.9797, -1.0183, -0.9676, -1.0210, -0.4526, -0.6071],\n",
      "        [-0.9420,  0.2685, -1.0176, -0.9861, -1.0485, -1.0447, -0.9103, -0.8474,\n",
      "         -0.9747, -0.9856, -0.9576, -0.9796, -0.7072, -0.7940],\n",
      "        [-0.3425, -0.6431, -0.6632, -1.0699, -1.0286,  0.2038, -1.0860, -1.0727,\n",
      "         -0.8977, -1.0534, -0.9325, -1.1341, -0.5710, -0.3779],\n",
      "        [-0.5001, -0.7323, -0.8946, -0.9696, -0.9672,  0.0978, -0.9550, -0.9847,\n",
      "         -1.0110, -0.9632, -0.9493, -1.0602, -0.3354, -0.6563],\n",
      "        [-0.7799, -0.0739, -0.9381, -1.0312, -1.1089, -0.2442, -1.0077, -1.0827,\n",
      "         -0.9668, -1.0146, -1.0098, -1.1012, -0.8223, -0.7084],\n",
      "        [-0.9290,  0.1654, -1.0196, -0.9897, -1.0359, -1.0093, -0.9130, -0.7482,\n",
      "         -0.9658, -0.9832, -0.9857, -0.9870, -0.6664, -0.7414],\n",
      "        [-0.9027,  0.2234, -1.0334, -0.9277, -1.0549, -1.0255, -0.9107, -0.8632,\n",
      "         -0.9869, -0.9810, -0.9469, -0.9611, -0.6536, -0.8316],\n",
      "        [-0.8824, -0.2290, -0.9450, -0.9751, -1.0596, -0.6999, -1.0240, -0.9999,\n",
      "         -0.9638, -1.0269, -0.9783, -1.0030, -0.2921, -0.1968],\n",
      "        [-1.0112,  0.1164, -1.0285, -1.0477, -1.0498, -1.0492, -0.9981, -0.6973,\n",
      "         -0.9973, -1.0075, -0.9759, -1.0580, -0.7861, -0.7133]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#example: how to load and predict\n",
    "import torch\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "import pickle\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "model = AttentiveFP(in_channels=24, hidden_channels=200, out_channels=14,\n",
    "                    edge_dim=11, num_layers=2, num_timesteps=2,\n",
    "                    dropout=0.0)\n",
    "model.load_state_dict(torch.load(\"/localhome/cschiebroek/other/Digital_Chemistry/sandbox/models/example_MTL_seed_18012000.pt\"))\n",
    "model.eval()\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_graphs_DASH_charge_scaled = get_graphs(train,dash_charges=True,scaled =True,save_graphs = True)\n",
    "train_loader = DataLoader(train_graphs_DASH_charge_scaled, batch_size=32, shuffle=False)\n",
    "for data in train_loader:\n",
    "    out = model(data.x, data.edge_index, data.edge_attr,data.batch)\n",
    "    print(out)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5214, -0.7871, -0.9921, -0.9109, -0.9067, -0.1491, -0.9188, -0.9088,\n",
      "         -1.0701, -0.9206, -0.9765, -1.0306, -0.0363, -0.8770],\n",
      "        [-0.4625, -0.4841, -0.8560, -0.9216, -1.0713, -0.1384, -0.9661, -0.9778,\n",
      "         -0.9552, -0.9406, -0.9719, -1.0371, -0.6547, -0.2935],\n",
      "        [-0.6098, -0.2845, -0.8240, -0.9208, -1.0263, -0.2171, -0.9865, -0.9963,\n",
      "         -0.8447, -0.9473, -0.9377, -0.9593, -0.0413, -0.2785],\n",
      "        [-0.9883, -0.9365, -1.0168, -1.1672, -1.0389, -1.1151, -1.1015, -0.6023,\n",
      "         -1.0092, -1.0607, -1.0325, -1.1102, -0.0531,  0.5089],\n",
      "        [-0.1845, -0.6231, -0.5642, -1.0305, -0.9269,  0.4017, -1.0493, -1.0526,\n",
      "         -0.8965, -1.0288, -0.9095, -1.0694, -0.4504, -0.4449],\n",
      "        [-0.3976, -0.5278, -0.6276, -1.0880, -1.0510, -0.0174, -1.0960, -1.1113,\n",
      "         -0.7685, -0.9971, -0.9589, -1.0912, -0.3168, -0.3657],\n",
      "        [-0.6970, -0.0869, -0.9033, -0.8946, -1.0130, -0.1053, -0.9602, -0.9756,\n",
      "         -0.9136, -0.9233, -0.9744, -0.9624, -0.0310, -0.6538],\n",
      "        [-0.8754,  0.1796, -1.0149, -0.9531, -1.0465, -1.0357, -0.8926, -0.8793,\n",
      "         -0.9811, -0.9570, -0.9631, -0.9245, -0.5721, -0.6603],\n",
      "        [-0.7011,  0.2119, -0.9674, -0.9192, -1.0639, -1.1155, -0.8815, -0.9389,\n",
      "         -0.9876, -0.8716, -0.9855, -0.8401, -0.7210, -0.0974],\n",
      "        [-0.9005,  0.2235, -1.0148, -0.9832, -1.0404, -0.9125, -0.9427, -0.9905,\n",
      "         -0.9918, -0.9795, -0.9575, -0.9770, -0.6233, -0.8041],\n",
      "        [-0.8625,  0.0841, -1.0164, -0.9715, -1.0217, -0.7341, -0.9486, -0.9911,\n",
      "         -0.9990, -0.9728, -0.9665, -0.9679, -0.4140, -0.7758],\n",
      "        [-0.8372, -0.0084, -0.9803, -0.9949, -1.0487, -0.7290, -0.9399, -0.8667,\n",
      "         -0.9724, -0.9981, -0.9901, -1.0003, -0.5494, -0.7259],\n",
      "        [ 0.0113, -0.5527, -0.3606, -1.0264, -0.9419,  0.3308, -1.0795, -1.0541,\n",
      "         -0.7178, -1.0090, -0.7804, -1.0483, -0.5487, -0.1176],\n",
      "        [-0.9459,  0.0311, -1.0140, -0.9816, -1.0309, -0.9925, -0.9886, -0.9334,\n",
      "         -1.0022, -0.9904, -0.9862, -0.9641, -0.4914, -0.4344],\n",
      "        [-0.6400, -0.6942, -0.9947, -0.9971, -1.0149,  0.0777, -1.0744, -1.0763,\n",
      "         -1.0366, -1.0350, -1.0263, -1.0721, -0.0747, -0.7102],\n",
      "        [-0.9064,  0.3136, -1.0379, -0.9906, -1.0506, -0.9855, -0.9161, -0.9346,\n",
      "         -0.9662, -0.9906, -0.9839, -0.9192, -0.8085, -0.6566],\n",
      "        [-0.9328,  0.1878, -1.0456, -1.0021, -1.0349, -0.9997, -0.9438, -0.8801,\n",
      "         -0.9946, -0.9960, -0.9665, -0.9868, -0.6669, -0.7338],\n",
      "        [-0.9432,  0.2232, -1.0495, -1.0058, -1.0364, -1.0221, -0.9406, -0.8629,\n",
      "         -0.9985, -0.9977, -0.9652, -0.9853, -0.6978, -0.7581],\n",
      "        [-0.8370, -0.0263, -0.9929, -0.9996, -1.0555, -0.6039, -0.9878, -1.0059,\n",
      "         -0.9814, -0.9914, -0.9734, -0.9948, -0.5061, -0.6332],\n",
      "        [-0.9477,  0.3694, -1.0520, -1.0082, -1.0369, -1.0032, -0.9377, -0.9428,\n",
      "         -0.9674, -1.0012, -0.9832, -0.9897, -0.8888, -0.8533],\n",
      "        [-0.8956,  0.2531, -1.0151, -1.0233, -1.0492, -0.7814, -0.9759, -1.0544,\n",
      "         -0.9714, -1.0208, -0.9693, -1.0173, -0.8046, -0.7624],\n",
      "        [-0.9024,  0.2339, -1.0394, -0.9541, -1.0596, -1.0340, -0.8764, -0.8113,\n",
      "         -0.9805, -0.9707, -0.9582, -0.9351, -0.6950, -0.7878],\n",
      "        [-0.8927,  0.2060, -1.0028, -0.9813, -1.0361, -0.9501, -0.9454, -0.9770,\n",
      "         -0.9739, -0.9827, -0.9671, -0.9507, -0.5859, -0.6233],\n",
      "        [-0.8954, -0.0169, -0.9941, -1.0129, -1.0707, -0.6814, -1.0192, -1.0364,\n",
      "         -0.9797, -1.0183, -0.9676, -1.0210, -0.4526, -0.6071],\n",
      "        [-0.9420,  0.2685, -1.0176, -0.9861, -1.0485, -1.0447, -0.9103, -0.8474,\n",
      "         -0.9747, -0.9856, -0.9576, -0.9796, -0.7072, -0.7940],\n",
      "        [-0.3425, -0.6431, -0.6632, -1.0699, -1.0286,  0.2038, -1.0860, -1.0727,\n",
      "         -0.8977, -1.0534, -0.9325, -1.1341, -0.5710, -0.3779],\n",
      "        [-0.5001, -0.7323, -0.8946, -0.9696, -0.9672,  0.0978, -0.9550, -0.9847,\n",
      "         -1.0110, -0.9632, -0.9493, -1.0602, -0.3354, -0.6563],\n",
      "        [-0.7799, -0.0739, -0.9381, -1.0312, -1.1089, -0.2442, -1.0077, -1.0827,\n",
      "         -0.9668, -1.0146, -1.0098, -1.1012, -0.8223, -0.7084],\n",
      "        [-0.9290,  0.1654, -1.0196, -0.9897, -1.0359, -1.0093, -0.9130, -0.7482,\n",
      "         -0.9658, -0.9832, -0.9857, -0.9870, -0.6664, -0.7414],\n",
      "        [-0.9027,  0.2234, -1.0334, -0.9277, -1.0549, -1.0255, -0.9107, -0.8632,\n",
      "         -0.9869, -0.9810, -0.9469, -0.9611, -0.6536, -0.8316],\n",
      "        [-0.8824, -0.2290, -0.9450, -0.9751, -1.0596, -0.6999, -1.0240, -0.9999,\n",
      "         -0.9638, -1.0269, -0.9783, -1.0030, -0.2921, -0.1968],\n",
      "        [-1.0112,  0.1164, -1.0285, -1.0477, -1.0498, -1.0492, -0.9981, -0.6973,\n",
      "         -0.9973, -1.0075, -0.9759, -1.0580, -0.7861, -0.7133]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "torch.save(model,'model_full_test.pt')\n",
    "#load model\n",
    "model = torch.load('model_full_test.pt')\n",
    "train_loader = DataLoader(train_graphs_DASH_charge_scaled, batch_size=32, shuffle=False)\n",
    "for data in train_loader:\n",
    "    out = model(data.x, data.edge_index, data.edge_attr,data.batch)\n",
    "    print(out)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.nn.models.attentive_fp.AttentiveFP"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtl_dc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
