{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: excluded:\n",
    "- data_pKA = read_sdf(pKA_path, 'pKa')\n",
    "- data_RBiodeg = read_sdf(RBiodeg_path, 'RBiodeg') binary\n",
    "- data_CoMPARA = read_sdf(CoMPARA_path, 'CoMPARA'), mixed \n",
    "- data_CATMOS = read_sdf(CATMOS_path, 'CATMOS') mixed\n",
    "- data_CERAPP = read_sdf(CERAPP_path, 'CERAPP') mixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from utils_data import load_data,scale_props,get_graphs\n",
    "from utils_plotting import plot_property_histograms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils_model import train_and_validate_multi,get_preds_per_task,preds_and_ys_to_df\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_combined = load_data()\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plot_property_histograms(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_scaled,scaler = scale_props(df_combined)\n",
    "#save the scaler\n",
    "scaler.save('scaler.pkl')\n",
    "plot_property_histograms(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#split check: if we do a random split 80/20, do we also get a 80/20 split for each property?\n",
    "train, test = train_test_split(df_scaled, test_size=0.2, random_state=42)\n",
    "for col in df_scaled.columns[1:]:\n",
    "    print(f'{col}: {test[col].count()/df_scaled[col].count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#check if for each property the distribution is similar in train and test\n",
    "from scipy.stats import mannwhitneyu\n",
    "for col in df_scaled.columns[1:]:\n",
    "    train_tmp = train[col].dropna()\n",
    "    test_tmp = test[col].dropna()\n",
    "    print(f'{col}: {mannwhitneyu(train_tmp,test_tmp)}')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "for col in df_scaled.columns[1:]:\n",
    "    plt.boxplot(x=[train[col].dropna(),test[col].dropna()],labels=['train','test'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#count duplicated smiles\n",
    "print(f'duplicated smiles: {df_scaled.SMILES.duplicated().sum()}')\n",
    "#lets save these splits\n",
    "train.to_csv('train.csv',index=False)\n",
    "test.to_csv('test.csv',index=False)\n",
    "print(len(train),len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# train_graphs_no_charge_scaled = get_graphs(train,dash_charges=False,scaled =True,save_graphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_graphs_DASH_charge_scaled = get_graphs(train,dash_charges=True,scaled =True,save_graphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "outputs = 14\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_data, val_data = train_test_split(train_graphs_DASH_charge_scaled, test_size=0.2, random_state=2000)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "model= AttentiveFP(in_channels=24, hidden_channels=200, out_channels=outputs, #note that using the DASH graphs will increase the amount of node feauters (input channels for model) from 23 to 24\n",
    "                            edge_dim=11, num_layers=4, num_timesteps=2,\n",
    "                            dropout=0.0).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=10**-3,\n",
    "                        weight_decay=10**-4)\n",
    "print(len(train_data), len(val_data))\n",
    "train_and_validate_multi(model, train_loader, val_loader, optimizer, num_epochs=100, outputs=outputs, verbose=True,props_to_train=['LogVP','LogP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "preds, ys = get_preds_per_task(model,val_loader, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#make df from preds\n",
    "model= AttentiveFP(in_channels=24, hidden_channels=200, out_channels=outputs,\n",
    "                        edge_dim=11, num_layers=4, num_timesteps=2,\n",
    "                        dropout=0.0).to(device)\n",
    "model.load_state_dict(torch.load('test_model.pt'))\n",
    "df_preds,df_ys = preds_and_ys_to_df(preds,ys,ref_df = df_combined,scaler = scaler,props_to_train=['LogVP','LogP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'OPERA_MTL' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n OPERA_MTL ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plot\n",
    "from utils_plotting import plot_scatters\n",
    "plot_scatters(df_preds,df_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "1. Add the different endpoints - check\n",
    "2. Normalization of values\n",
    "3. Weighting of the tasks\n",
    "4. Hyperparameter optimization\n",
    "5. Benchmarking datasets? E.g. SAMPL7 for logP\n",
    "6. Quadruple check refs - check\n",
    "7. Think about datasplitting: same splits as OPERA? possible? otherwise, just cross-val? or random splits (multiple)\n",
    "8. Different random weight initializations of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split: 80/20 5x\n",
    "\n",
    "HP OPT: https://docs.ray.io/en/latest/tune/api/doc/ray.tune.search.bayesopt.BayesOptSearch.html\n",
    "Repeated K-fold: https://greglandrum.github.io/rdkit-blog/posts/2023-08-13-xval-variability1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
